{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c4885d-f0a2-4801-90f1-078e588c9ccf",
   "metadata": {},
   "source": [
    "# Regular Expression Handlind version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6dec691-4029-4182-a439-208831ff43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lists to store parsed iterations and losses\n",
    "iterations = []\n",
    "losses = []\n",
    "\n",
    "# Regex pattern to capture iteration number and reduced_train_loss\n",
    "pattern = re.compile(\n",
    "    r'Training epoch \\d+,\\s*iteration\\s+(\\d+)/\\d+\\s*\\|\\s*lr:[^|]+\\|\\s*global_batch_size:[^|]+\\|\\s*global_step:\\s*\\d+\\s*\\|\\s*reduced_train_loss:\\s*([0-9]*\\.?[0-9]+(?:e[-+]?\\d+)?)'\n",
    ")\n",
    "\n",
    "# Path to the log file\n",
    "log_file_path = '/datasets/soc-20250703225140/nemotron_sft_output.log'\n",
    "\n",
    "# Read and parse the log file\n",
    "with open(log_file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        match = pattern.search(line)\n",
    "        if match:\n",
    "            iter_num = int(match.group(1))\n",
    "            loss_val = float(match.group(2))\n",
    "            iterations.append(iter_num)\n",
    "            losses.append(loss_val)\n",
    "\n",
    "# Plotting\n",
    "plt.figure()\n",
    "plt.plot(iterations, losses, marker='o', linestyle='-')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Reduced Training Loss')\n",
    "plt.title('Training Loss vs Iteration')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a694915-a618-4ed0-a717-9da8c565b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lists to store parsed training and validation metrics\n",
    "train_iterations = []\n",
    "train_losses = []\n",
    "val_steps = []\n",
    "val_losses = []\n",
    "\n",
    "# Regex patterns\n",
    "train_pattern = re.compile(\n",
    "    r'Training epoch \\d+,\\s*iteration\\s+(\\d+)/\\d+\\s*\\|\\s*lr:[^|]+\\|\\s*global_batch_size:[^|]+\\|\\s*global_step:\\s*\\d+\\s*\\|\\s*reduced_train_loss:\\s*([0-9]*\\.?[0-9]+(?:e[-+]?\\d+)?)'\n",
    ")\n",
    "val_pattern = re.compile(\n",
    "    r\"Epoch\\s+\\d+,\\s*global step\\s+(\\d+):\\s*'val_loss'\\s*reached\\s*([0-9]*\\.?[0-9]+(?:e[-+]?\\d+)?)\"\n",
    ")\n",
    "\n",
    "# Path to the log file\n",
    "log_file_path = '/datasets/soc-20250703225140/nemotron_sft_output.log'\n",
    "\n",
    "# Read and parse the log file\n",
    "with open(log_file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        t_match = train_pattern.search(line)\n",
    "        if t_match:\n",
    "            train_iterations.append(int(t_match.group(1)))\n",
    "            train_losses.append(float(t_match.group(2)))\n",
    "        v_match = val_pattern.search(line)\n",
    "        if v_match:\n",
    "            val_steps.append(int(v_match.group(1)))\n",
    "            val_losses.append(float(v_match.group(2)))\n",
    "\n",
    "# Plot and save training loss\n",
    "plt.figure()\n",
    "plt.plot(train_iterations, train_losses, marker='o', linestyle='-')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Reduced Training Loss')\n",
    "plt.title('Training Loss vs Iteration')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_loss.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot and save validation loss\n",
    "plt.figure()\n",
    "plt.plot(val_steps, val_losses, marker='o', linestyle='-')\n",
    "plt.xlabel('Global Step')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss vs Global Step')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('validation_loss.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408707a5-435d-4f35-bd3c-1d985957fad8",
   "metadata": {},
   "source": [
    "# Tensorboard Parsing Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7f5c133-e120-4b9a-9ee0-4ced251c6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import tensor_util\n",
    "import os\n",
    "\n",
    "def get_values_tensorflow(filepath, tag, steps, values):\n",
    "    \"\"\"\n",
    "    Parses a TensorBoard event file for the given tag.\n",
    "    Appends event.step to 'steps' and the scalar value (from tensor or simple_value) to 'values'.\n",
    "    \"\"\"\n",
    "    for event in tf.compat.v1.train.summary_iterator(filepath):\n",
    "        for value in event.summary.value:\n",
    "            if value.tag == tag:\n",
    "                # Try tensor field first\n",
    "                try:\n",
    "                    arr = tensor_util.MakeNdarray(value.tensor)\n",
    "                    val = arr.item(0)\n",
    "                except (TypeError, AttributeError, ValueError):\n",
    "                    # Fallback to simple_value for scalar summaries\n",
    "                    val = value.simple_value\n",
    "                steps.append(event.step)\n",
    "                values.append(val)\n",
    "\n",
    "def create_loss_graphs(event_files_folder_path, experiment_name, saving_folder_path):\n",
    "    \"\"\"\n",
    "    Reads all event files in the folder, extracts train & val loss, and saves PNG graphs.\n",
    "    \"\"\"\n",
    "    # Tags used in your NeMo logs\n",
    "    train_tag = \"reduced_train_loss\"\n",
    "    val_tag = \"val_loss\"\n",
    "\n",
    "    # Collect event file names\n",
    "    event_files = [f for f in os.listdir(event_files_folder_path) if f.startswith(\"events\")]\n",
    "    \n",
    "    # Extract train loss\n",
    "    train_steps, train_vals = [], []\n",
    "    for f in event_files:\n",
    "        get_values_tensorflow(os.path.join(event_files_folder_path, f), train_tag, train_steps, train_vals)\n",
    "    # Extract val loss\n",
    "    val_steps, val_vals = [], []\n",
    "    for f in event_files:\n",
    "        get_values_tensorflow(os.path.join(event_files_folder_path, f), val_tag, val_steps, val_vals)\n",
    "\n",
    "    # Sort by step\n",
    "    train_data = sorted(zip(train_steps, train_vals))\n",
    "    val_data = sorted(zip(val_steps, val_vals))\n",
    "\n",
    "    # Unzip\n",
    "    ts, tv = zip(*train_data) if train_data else ([], [])\n",
    "    vs, vv = zip(*val_data) if val_data else ([], [])\n",
    "\n",
    "    # Plot and save\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(ts, tv, marker='o', linestyle='-')\n",
    "    plt.title(f\"{experiment_name} - Train Loss\")\n",
    "    plt.xlabel(\"Global Step\")\n",
    "    plt.ylabel(\"Reduced Training Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(saving_folder_path, \"train_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(vs, vv, marker='o', linestyle='-')\n",
    "    plt.title(f\"{experiment_name} - Validation Loss\")\n",
    "    plt.xlabel(\"Global Step\")\n",
    "    plt.ylabel(\"Validation Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(saving_folder_path, \"val_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Example usage:\n",
    "# create_loss_graphs(\"/datasets/soc-20250703225140/nemo_checkpoints/nemotron_49b_super_custom_finetune/tb_logs\", \n",
    "#                    \"nemotron_49b_super_custom_finetune\", \"/datasets/soc-20250703225140/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b3d479e-a4a9-4e9e-b985-96e1d4ea4af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lr', 'global_batch_size', 'global_step', 'reduced_train_loss', 'grad_norm', 'num_zeros_in_grad', 'train_step_timing in s', 'consumed_samples', 'validation_step_timing in s', 'val_loss', 'epoch']\n"
     ]
    }
   ],
   "source": [
    "event_files = [filename for filename in os.listdir(event_files_folder_path) if 'events.out.' in filename]\n",
    "event_files.sort()    \n",
    "tags = get_tags(os.path.join(event_files_folder_path, event_files[0]))\n",
    "print(tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
